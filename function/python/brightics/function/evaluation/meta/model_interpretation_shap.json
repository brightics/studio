{
    "script": {
        "type": "",
        "content": ""
    },
    "specJson": {
        "id": "",
        "category": "evaluation",
        "func": "brightics.function.evaluation$model_interpretation_shap26916",
        "name": "brightics.function.evaluation$model_interpretation_shap",
        "context": "python",
        "label": "Model Interpretation (SHAP)",
        "summary": "This function interprets a given model.",
        "tutorialLink": "",
        "description": "",
        "tags": [
            "shap",
            "plots",
            "shap plots",
            "feature",
            "importance",
            "feature importance",
            "model",
            "interpretation",
            "model interpretation"
        ],
        "version": "3.6",
        "inputs": {
            "table": "",
            "model": ""
        },
        "outputs": {
            "out_model": "",
            "out_table": ""
        },
        "meta": {
            "table": {
                "type": "table",
                "desc": "",
                "optional": false
            },
            "model": {
                "type": "model",
                "desc": "",
                "optional": false
            },
            "out_model": {
                "type": "model",
                "desc": ""
            },
            "out_table": {
                "type": "table",
                "desc": ""
            }
        },
        "params": [
            {
                "id": "plot_types",
                "label": "Plot Types",
                "description": "",
                "visibleOption": [],
                "control": "CheckBox",
                "validation": [],
                "globalVariable": false,
                "type": "String",
                "items": [
                    {
                        "label": "Bar",
                        "value": "Bar",
                        "default": true,
                        "item": ""
                    },
                    {
                        "label": "Decision",
                        "value": "Decision",
                        "default": true,
                        "item": ""
                    },
                    {
                        "label": "Beeswarm",
                        "value": "Beeswarm",
                        "default": true,
                        "item": ""
                    },
                    {
                        "label": "Scatter",
                        "value": "Scatter",
                        "default": true,
                        "item": ""
                    },
                    {
                        "label": "Heatmap",
                        "value": "Heatmap",
                        "default": true,
                        "item": ""
                    }
                ]
            },
            {
                "id": "bar_global_local",
                "label": "Bar Option",
                "description": "",
                "visibleOption": [
                    {
                        "id": "plot_types",
                        "value": "Bar"
                    }
                ],
                "control": "CheckBox",
                "validation": [],
                "globalVariable": false,
                "type": "String",
                "items": [
                    {
                        "label": "Global",
                        "value": "global",
                        "default": true,
                        "item": ""
                    },
                    {
                        "label": "Local",
                        "value": "local",
                        "default": false,
                        "item": ""
                    }
                ]
            },
            {
                "id": "bar_data_row",
                "label": "Bar Data Row",
                "description": "",
                "visibleOption": [
                    {
                        "id": "bar_global_local",
                        "value": "local"
                    },
                    {
                        "id": "plot_types",
                        "value": "Bar"
                    }
                ],
                "control": "ArrayInput",
                "validation": [],
                "mandatory": false,
                "globalVariable": false,
                "placeHolder": "",
                "type": "Integer"
            },
            {
                "id": "decision_global_local",
                "label": "Decision Option",
                "description": "",
                "visibleOption": [
                    {
                        "id": "plot_types",
                        "value": "Decision"
                    }
                ],
                "control": "CheckBox",
                "validation": [],
                "mandatory": false,
                "globalVariable": false,
                "placeHolder": "",
                "type": "String",
                "items": [
                    {
                        "label": "Global",
                        "value": "global",
                        "default": true,
                        "item": ""
                    },
                    {
                        "label": "Local",
                        "value": "local",
                        "default": false,
                        "item": ""
                    }
                ]
            },
            {
                "id": "decision_data_row",
                "label": "Decision Data Row",
                "description": "",
                "visibleOption": [
                    {
                        "id": "plot_types",
                        "value": "Decision"
                    },
                    {
                        "id": "decision_global_local",
                        "value": "local"
                    }
                ],
                "control": "ArrayInput",
                "validation": [],
                "mandatory": false,
                "globalVariable": false,
                "placeHolder": "",
                "type": "Integer"
            },
            {
                "id": "decision_feature_order",
                "label": "Decision Feature Order",
                "description": "",
                "visibleOption": [
                    {
                        "id": "plot_types",
                        "value": "Decision"
                    }
                ],
                "control": "RadioButton",
                "validation": [],
                "mandatory": false,
                "globalVariable": false,
                "placeHolder": "",
                "type": "String",
                "items": [
                    {
                        "label": "Feature Importance",
                        "value": "importance",
                        "default": true,
                        "item": ""
                    },
                    {
                        "label": "Hierarchical Clustering",
                        "value": "hclust",
                        "default": false,
                        "item": ""
                    },
                    {
                        "label": "None",
                        "value": "none",
                        "default": false,
                        "item": ""
                    }
                ]
            },
            {
                "id": "max_display",
                "label": "Max Display",
                "description": "",
                "visibleOption": [],
                "control": "InputBox",
                "validation": [],
                "mandatory": false,
                "globalVariable": false,
                "placeHolder": "11",
                "type": "Integer",
                "defaultValue": "",
                "min": 1
            }
        ]
    },
    "md": {
        "en": "# Model interpretation (SHAP)\nThis function interprets a regression(or classification) model using SHAP.\n\n## Description\n'Model interpretation' explains how models have achieved results so that humans can understand it.\nEven if the model has good performance, it is dangerous to trust the model completely.\nBecause if a model derives the predict from the wrong basis, then it is not possible to get the right answer from new data.\nThus, more careful decision-making is needed in the field dealing with life such as medical care or autonomous driving.\nAlso, model interpretation is a useful method to find bias of models.\n\nSHAP measures the contribution of each feature to the result based on the Shapley value.\nIn addition, SHAP is a model-agnostic method and can interpret the model both globally and locally.\n\nReference\n+ <https://christophm.github.io/interpretable-ml-book/shap.html>\n+ <https://github.com/slundberg/shap>\n+ <https://en.wikipedia.org/wiki/Shapley_value>\n\n\n## Properties\n### VA\n#### INPUT\n1. **table**<b style=\"color:red\">*</b>: (Table) Training data.\n2. **model**<b style=\"color:red\">*</b>: (Model) A regression(or classification) model.\n#### OUTPUT\n1. **out_model**: (Model) Result of model interpretation\n2. **out_table**: (Table) Feature Importance table.\n#### PARAMETER\n1. **Sampling**: Whether to use data sampling. If set to False, use all data.  \n\t* Default: True\n\n2. **Sample Size**: The number of samples\n\t* Default: 500  \n\n3. **Seed**: Random seed for sampling \n\t* Default: 1  \n\n4. **Plot Types**: Choose plots to use \n    * Available Options: \n    `Bar`: A bar chart that presents feature importance.\n\t`Decision`: A broken line graph that shows decision procedure of the model.\n    `Beeswarm`: Distribution of SHAP values. The color of each point depends on the original value of the data.\n    `Scatter`: The change of SHAP values according to the value of each feature. The interaction effects appear in vertical differences of SHAP values.\n    `Heatmap`: A heatmap of SHAP values. Data are ordered by clustering.\n\n5. **Bar Option**: Select options to use the bar plot.(Use only when 'Plot types' has 'Bar'.)\n    * Available Options: (select one or more)\t\n    `Global`: Shows the average influence of each feature on the entire data.\n    `Local`: Shows the interpretation result for the input rows.\n\n6. **Bar Data Row**: Enter the indices of the data rows to be interpreted.(Use only when 'Bar Option' has 'Local'.)\n Default:[1].  \n\n7. **Decision Option**:  Select options to use the decision plot.(Use only when 'Plot Types' has 'Decision'.)\n    * Available Options: (select one or more)\t\n    `Global`: Shows the entire data.\n    `Local`: Shows the interpretation result for the input rows.\n\n8. **Decision Data Row**: Enter the indices of the data rows to be interpreted.(Use only when 'Decision Option' has 'Local'.)\nDefault:[1].  \n\n9. **Decision Feature Order**: Criteria for sorting features\n    * Available Options:    \n    `Feature Importance`: Sort by absolute value of SHAP values.\n    `Hierarchical Clustering`: Sort by hierarchical clustering.\n    `None`: Keep original order. \n\n10. **Max Display**: Number of features to display the result.\nIf the number of features is less than or equal to the Max Display value, all features are displayed.\n\t* Default: 11 \n\n### Python\n#### USAGE\n\n```\nmodel_interpretation_shap(table = , model = , sampling = , sample_size = , seed = , plot_types = , bar_global_local = , bar_data_row = , decision_global_local = , decision_data_row = , decision_feature_order = , max_display = )\n```\n\n#### INPUT\n1. **table**<b style=\"color:red\">*</b>: (Table) Training data\n2. **model**<b style=\"color:red\">*</b>: (Model) A regression(or classification) model\n#### OUTPUT\n1. **out_model**: (Model) Result of model interpretation\n2. **out_table**: (Table) Feature Importance table.\n#### PARAMETER\n1. **sampling**: Whether to use data sampling. If set to False, use all data.\n\t* Type: *bool*\n\t* Default: true \n2. **sample_size**:  The number of samples\n\t* Type: *int*\n\t* Default: 500 \n3. **seed**: Random seed for sampling\n\t* Type: *int*\n\t* Default: 1\n4. **plot_types**: Choose plots to use\n\t* Type: *list[str]*\n\t* Default / Range: Bar, Decision, Beeswarm, Scatter, Heatmap (Bar | Decision | Beeswarm | Scatter | Heatmap)\n5. **bar_global_local**: Select options to use the bar plot.\n\t* Type: *list[str]*\n\t* Default / Range: global ( global | local )\n6. **bar_data_row**: Enter the indices of the data rows to be interpreted.\n\t* Type: *list[int]*\n7. **decision_global_local**: Select options to use the decision plot.\n\t* Type: *list[str]*\n\t* Default / Range: global ( global | local )\n8. **decision_data_row**: Enter the indices of the data rows to be interpreted.\n\t* Type: *list[int]*\n9. **decision_feature_order**: Criteria for sorting features\n\t* Type: *str*\n\t* Default / Range: importance ( importance | hclust | none )\n10. **max_display**:  Number of features to display the result.\n\t* Type: *int*\n\t* Default / Range: 11\n\n\n## Example\n### VA\n\n**<a href=\"/static/help/python/sample_model/model_interpretation_shap.json\" download>[Sample Model]</a>**\n\n<img src=\"/static/help/python/sample_model_img/model_interpretation_shap.PNG\"  width=\"800px\" style=\"border: 1px solid gray\" >\n\n\n++Parameters++\n1. **Sampling**: True\n2. **Sample Size**:100\n3. **Seed**:1\n4. **Plot Types**</b>: Bar, Decision\n5. **Bar Option**: Global, Local\n6. **Bar Data Row**: [45, 90] \n7. **Decision Option**: Local\n8. **Decision Data Row**: [20, 60, 135]\n9. **Decision Feature Order**: Feature Importance\n10. **Max Display**: 11\n\n\n### Python\n\n```\nfrom brightics.function.regression import linear_regression_train\nfrom brightics.function.evaluation import model_interpretation_shap\n\ninput_table = inputs[0]\n\n\nlr_result = linear_regression_train(table=input_table,\n                                    feature_cols=['sepal_length', 'sepal_width'],\n                                    label_col='petal_width',\n                                    fit_intercept=True,\n                                    is_vif=True,\n                                    vif_threshold=10,\n                                    group_by=None)\n                                    \ntrained_model = lr_result['model']\n\n\nres = model_interpretation_shap(table = input_table,\n                                 model = trained_model,\n                                 sampling = True,\n                                 sample_size = 100,\n                                 seed = 1, \n                                 plot_types = ['Bar', 'Decision'], \n                                 bar_global_local = ['Global', 'Local'],\n                                 bar_data_row = [45, 90], \n                                 decision_global_local = ['Local'],\n                                 decision_data_row = [20, 60, 135],\n                                 decision_feature_order = 'importance',\n                                 max_display = 11)\n                                 \nres['out_model']\n```\n\n",
        "kr": "# Model Interpretation (SHAP)\r\n\r\n이 함수는 SHAP을 사용하여 회귀(또는 분류) 모델의 해석을 제공한다.\r\n\r\n## Description\r\n모델 해석(model interpretation)이란 모델이 어떻게 결과를 얻었는지 인간이 이해할 수 있도록 설명한 것이다. \r\n단지 성능이 좋은 것 만으로는 모델을 완전히 신뢰하기는 어렵다.\r\n왜냐하면 모델이 결과를 잘못된 근거로부터 도출했다면, 새로운 데이터를 적용했을 때 올바른 결과를 기대할 수 없기 때문이다.\r\n따라서 의료 분야나 자율 주행같은 사람의 목숨이 걸린 일에는 좀 더 신중한 의사결정이 필요하다.\r\n또한 모델 해석은 모델의 편향을 찾는 좋은 방법이다.\r\n\r\nSHAP은 Shapley value를 기반으로 모델의 결과에 대한 각 feature의 기여도를 측정한다. \r\n또한 SHAP은 모델 불특정 기법으로서, 모델에 관계없이 사용할 수 있다. \r\nSHAP은 전역적, 국소적 해석을 모두 제공한다.\r\n\r\n\r\n참고자료\r\n\r\n+ <https://christophm.github.io/interpretable-ml-book/shap.html>\r\n+ <https://github.com/slundberg/shap>\r\n+ <https://en.wikipedia.org/wiki/Shapley_value>\r\n\r\n\r\n## Properties\r\n### VA\r\n#### INPUT\r\n1. **table**<b style=\"color:red\">*</b>: (Table) 모델 학습에 사용한 데이터.\r\n2. **model**<b style=\"color:red\">*</b>: (Model) 회귀(또는 분류) 모델. \r\n#### OUTPUT\r\n1. **out_model**: (Model) 모델 해석 결과.\r\n2. **out_table**: (Table) Feature Importance 테이블.\r\n#### PARAMETER\r\n1. **Sampling**: 데이터를 샘플링할지 여부 결정. 이 값이 False이면 모든 데이터를 사용.\r\n\t* Default: True \r\n2. **Sample Size**: 샘플의 갯수.\r\n\t* Default:  500\r\n3. **Seed**: 샘플링에 사용할 랜덤 시드.\r\n\t* Default: 1 \r\n4. **Plot Types**: 사용할 plot을 선택.\r\n    * Available Options: (여러 개 선택 가능)\t\r\n    `Bar`: 막대 그래프를 이용하여 모델의 feature importance를 보여줌.\r\n\t`Decision`: 꺾은선 그래프를 이용하여 모델의 결정과정을 보여줌.\r\n    `Beeswarm`: SHAP value의 분포를 보여줌. 각 점의 색깔은 데이터의 원래 값에 따라 변함.\r\n    `Scatter`: 각 feature의 값에 따른 SHAP value의 변화를 보여줌. 상호작용 효과가 세로축 방향의 변화로 나타남. \r\n    `Heatmap`: 히트맵을 이용하여 SHAP value를 보여줌. 데이터는 클러스터링을 이용하여 정렬.  \r\n\r\n5. **Bar Option**: Bar plot을 어떻게 사용할지 선택('Plot Types'에서 'Bar'를 선택했을 때만 사용).\r\n    * Available Options: (여러 개 선택 가능)\t\r\n    `Global`: 각 feature들이 전체 데이터에 평균적으로 미치는 영향력을 보여줌. \r\n    `Local`: 입력한 행의 해석 결과를 보여줌. \r\n\r\n6. **Bar Data Row**: 해석할 데이터 행의 인덱스를 입력.('Bar Option'에서 'Local'을 선택했을 때만 사용.)\r\n(기본값: [1]. 여러 개 입력 가능)\r\n\r\n7. **Decision Option**: Decision plot을 어떻게 사용할지 선택('Plot Types'에서 'Decision'을 선택했을 때만 사용.)  \r\n    * Available Options: (여러 개 선택 가능)    \r\n    `Global`: 모든 데이터의 해석 결과를 보여줌. \r\n    `Local`: 입력한 행의 해석 결과만 보여줌. \r\n\r\n8. **Decision Data Row**: 해석할 데이터 행의 인덱스를 입력.('Decision Option'에서 'Local'을 선택했을 때만 사용.)\r\n(기본값: [1]. 여러 개 입력 가능)\r\n\r\n9. **Decision Feature Order**: Feature를 정렬할 기준.\r\n    * Available Options:    \r\n    `Feature Importance`: SHAP value의 절댓값의 합이 큰 순서대로 정렬.\r\n    `Hierarchical Clustering`: 계층적 군집화를 통해 정렬.\r\n    `None`: 원래 순서 유지. \r\n\r\n10. **Max Display**: 결과를 표시할 feature의 갯수. \r\nFarture의 갯수가 Max Display 값보다 작거나 같으면 모든 feature를 다 표시함. \r\n\t* 기본값: 11 \r\n\r\n\r\n### Python\r\n#### USAGE\r\n\r\n```\r\nmodel_interpretation(table = , model = , sampling = , sample_size = , seed = , plot_types = , bar_global_local = , bar_data_row = , decision_global_local = , decision_data_row = , decision_feature_order = , max_display = )\r\n```\r\n\r\n#### INPUT\r\n1. **table**<b style=\"color:red\">*</b>: (Table) 모델 학습에 사용한 데이터.\r\n2. **model**<b style=\"color:red\">*</b>: (Model) 회귀 또는 분류 모델. \r\n#### OUTPUT\r\n1. **out_model**: (Model) 모델 해석 결과\r\n2. **out_table**: (Table) Feature Importance 테이블\r\n#### PARAMETER\r\n1. **sampling**: \r\n\t* Type: *bool*\r\n\t* Default: true \r\n2. **sample_size**: \r\n\t* Type: *int*\r\n\t* Default: 500\r\n3. **seed**: \r\n\t* Type: *int*\r\n\t* Default: 1\r\n\r\n4. **plot_types**: 사용할 plot을 선택\r\n\t* Type: *list[str]*\r\n\t* Default / Range: Bar, Decision, Beeswarm, Scatter, Heatmap ( Bar | Decision  | Beeswarm  | Scatter  | Heatmap )\r\n5. **bar_global_local**: Bar plot을 어떻게 사용할지 선택.\r\n\t* Type: *list[str]*\r\n\t* Default / Range: global ( global | local )\r\n6. **bar_data_row**: 해석할 row를 입력. \r\n\t* Type: *list[int]*\r\n7. **decision_global_local**: Decision plot을 어떻게 사용할지 선택\r\n\t* Type: *list[str]*\r\n\t* Default / Range: global ( global | local )\r\n8. **decision_data_row**: 해석할 row를 입력.\r\n\t* Type: *list[int]*\r\n9. **decision_feature_order**:  Feature를 정렬할 기준을 선택.\r\n\t* Type: *str*\r\n\t* Default / Range: importance ( importance | hclust | none )\r\n7. **max_display**: 결과를 표시할 feature의 갯수.\r\n\t* Type: *int*\r\n\t* Default / Range: 11\r\n\r\n\r\n## Example\r\n### VA\r\n\r\n**<a href=\"/static/help/python/sample_model/model_interpretation_shap.json\" download>[Sample Model]</a>**\r\n\r\n<img src=\"/static/help/python/sample_model_img/model_interpretation_shap.PNG\"  width=\"800px\" style=\"border: 1px solid gray\" >\r\n\r\n\r\n<br>이 튜토리얼은 붓꽃(iris) 데이터로 학습한 선형 회귀 모델을 Moel Intepretation(SHAP)으로 해석한 것이다. \r\n\r\n++Parameters++\r\n1. **Sampling**: True\r\n2. **Sample Size**:100\r\n3. **Seed**:1\r\n4. **Plot Types**: Bar, Decision\r\n5. **Bar Option**: Global, Local\r\n6. **Bar Data Row**: [45, 90] \r\n7. **Decision Option**: Local\r\n8. **Decision Data Row**: [20, 60, 135]\r\n9. **Decision Feature Order**: Feature Importance\r\n10. **Max Display**: 11\r\n\r\n\r\n\r\n\r\n### Python\r\n\r\n```\r\nfrom brightics.function.regression import linear_regression_train\r\nfrom brightics.function.evaluation import model_interpretation_shap\r\n\r\ninput_table = inputs[0]\r\n\r\n\r\nlr_result = linear_regression_train(table=input_table,\r\n                                    feature_cols=['sepal_length', 'sepal_width'],\r\n                                    label_col='petal_width',\r\n                                    fit_intercept=True,\r\n                                    is_vif=True,\r\n                                    vif_threshold=10,\r\n                                    group_by=None)\r\n                                    \r\ntrained_model = lr_result['model']\r\n\r\n\r\nres = model_interpretation_shap(table = input_table,\r\n                                 model = trained_model,\r\n                                 sampling = True,\r\n                                 sample_size = 100,\r\n                                 seed = 1, \r\n                                 plot_types = ['Bar', 'Decision'], \r\n                                 bar_global_local = ['Global', 'Local'],\r\n                                 bar_data_row = [45, 90], \r\n                                 decision_global_local = ['Local'],\r\n                                 decision_data_row = [20, 60, 135],\r\n                                 decision_feature_order = 'importance',\r\n                                 max_display = 11)\r\n                                 \r\nres['out_model']\r\n```\r\n\r\n"
    },
    "scriptExamples": []
}